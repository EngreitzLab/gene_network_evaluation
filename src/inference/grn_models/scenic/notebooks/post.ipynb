{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import scanpy as sc\n",
    "import loompy as lp\n",
    "import pandas as pd\n",
    "from pyscenic.cli.utils import load_signatures\n",
    "from scipy.stats import ttest_1samp\n",
    "from pyscenic.utils import add_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_p_value(importances):\n",
    "    _, p_value = ttest_1samp(importances, 0)\n",
    "    return p_value\n",
    "\n",
    "def regulon2sadj(\n",
    "    regulons,\n",
    "):\n",
    "    net_lst = []\n",
    "    for tf in regulons:\n",
    "        tf_name = tf.name.split(\"(\")[0]\n",
    "        tf_targets = tf.gene2weight\n",
    "        for target, weight in tf_targets.items():\n",
    "            net_lst.append([tf_name, target, weight])\n",
    "    net = pd.DataFrame(net_lst, columns=[\"TF\", \"target\", \"importance\"])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_loom = \"/cellar/users/aklie/data/datasets/neurips2021_small/analysis/scenic/2024_05_03/rna.loom\"\n",
    "path_scenic = \"/cellar/users/aklie/data/datasets/neurips2021_small/analysis/scenic/2024_05_03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting consolidation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/cellar/users/aklie/data/datasets/neurips2021_small/analysis/scenic/2024_05_03/run2_reg.csv',\n",
       " '/cellar/users/aklie/data/datasets/neurips2021_small/analysis/scenic/2024_05_03/run4_reg.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting consolidation...\")\n",
    "reg_csvs = sorted(glob.glob(os.path.join(path_scenic, \"*reg.csv\")))\n",
    "reg_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading regulons...\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m all_edges \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m reg_csv \u001b[39min\u001b[39;00m reg_csvs:\n\u001b[0;32m----> 4\u001b[0m     regulons \u001b[39m=\u001b[39m load_signatures(reg_csv)\n\u001b[1;32m      5\u001b[0m     adj_df \u001b[39m=\u001b[39m regulon2sadj(regulons)\n\u001b[1;32m      6\u001b[0m     all_edges \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([all_edges, adj_df])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pyscenic/cli/utils.py:217\u001b[0m, in \u001b[0;36mload_signatures\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    214\u001b[0m extension \u001b[39m=\u001b[39m PurePath(fname)\u001b[39m.\u001b[39msuffixes\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m is_valid_suffix(extension, \u001b[39m\"\u001b[39m\u001b[39mctx\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39m# csv/tsv\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mreturn\u001b[39;00m df2regulons(load_motifs(fname, sep\u001b[39m=\u001b[39msuffixes_to_separator(extension)))\n\u001b[1;32m    218\u001b[0m \u001b[39melif\u001b[39;00m is_valid_suffix(extension, \u001b[39m\"\u001b[39m\u001b[39mctx_yaml\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m load_from_yaml(fname)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pyscenic/utils.py:447\u001b[0m, in \u001b[0;36mload_motifs\u001b[0;34m(fname, sep)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39m:param fname:\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39m:param sep:\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m COLUMN_NAME_CONTEXT, COLUMN_NAME_TARGET_GENES\n\u001b[0;32m--> 447\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m    448\u001b[0m     fname, sep\u001b[39m=\u001b[39msep, index_col\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], header\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], skipinitialspace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    450\u001b[0m df[(\u001b[39m\"\u001b[39m\u001b[39mEnrichment\u001b[39m\u001b[39m\"\u001b[39m, COLUMN_NAME_CONTEXT)] \u001b[39m=\u001b[39m df[\n\u001b[1;32m    451\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mEnrichment\u001b[39m\u001b[39m\"\u001b[39m, COLUMN_NAME_CONTEXT)\n\u001b[1;32m    452\u001b[0m ]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m s: \u001b[39meval\u001b[39m(s))\n\u001b[1;32m    453\u001b[0m df[(\u001b[39m\"\u001b[39m\u001b[39mEnrichment\u001b[39m\u001b[39m\"\u001b[39m, COLUMN_NAME_TARGET_GENES)] \u001b[39m=\u001b[39m df[\n\u001b[1;32m    454\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mEnrichment\u001b[39m\u001b[39m\"\u001b[39m, COLUMN_NAME_TARGET_GENES)\n\u001b[1;32m    455\u001b[0m ]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m s: \u001b[39meval\u001b[39m(s))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1747\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1744\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1746\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[1;32m   1748\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1749\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:92\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     89\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     91\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     96\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/test_scenicplus_dev/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "print(\"Reading regulons...\")\n",
    "all_edges = pd.DataFrame()\n",
    "for reg_csv in reg_csvs:\n",
    "    regulons = load_signatures(reg_csv)\n",
    "    adj_df = regulon2sadj(regulons)\n",
    "    all_edges = pd.concat([all_edges, adj_df])\n",
    "all_edges.head()\n",
    "print(f\"Total edges: {len(all_edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grouping by source and target and filtering edges...\")\n",
    "grouped = all_edges.groupby(['TF', 'target'])\n",
    "filtered = grouped.filter(lambda x: len(x) > 1)\n",
    "print(f\"{len(all_edges) - len(filtered)} edges dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean importance for each edge...\")\n",
    "mean_importance = filtered.groupby(['TF', 'target'])['importance'].mean()\n",
    "print(f\"Total unique edges: {len(mean_importance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating empirical p-value...\")\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "TINY = np.finfo(np.float32).tiny\n",
    "p_values_series = filtered.groupby(['TF', 'target'])['importance'].progress_apply(calc_p_value)\n",
    "p_values = p_values_series.values + TINY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transforming values...\")\n",
    "neg_log_p = -np.log10(p_values)\n",
    "normalized_importance = (mean_importance - mean_importance.min()) / (mean_importance.max() - mean_importance.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding correlation...\")\n",
    "adata = sc.read_loom(path_loom, sparse=True)\n",
    "filtered = add_correlation(filtered, adata.to_df())\n",
    "mean_corr = filtered.groupby(['TF', 'target'])['rho'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated = pd.DataFrame({\n",
    "    'source': mean_importance.index.get_level_values('TF'),\n",
    "    'target': mean_importance.index.get_level_values('target'),\n",
    "    'weight_signed': np.nan,\n",
    "    'weight_unsigned': mean_importance.values,\n",
    "    'weight_minmax_normalized': normalized_importance.values,\n",
    "    'p': p_values,\n",
    "    '-logp': neg_log_p,\n",
    "    'description': np.nan,\n",
    "    'corr': mean_corr.values if path_loom is not None else np.nan\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove self-loops\n",
    "print(\"Removing self-loops...\")\n",
    "consolidated = consolidated[consolidated[\"source\"] != consolidated[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "output_path = os.path.join(args.scenic_out_dir, args.out_file)\n",
    "consolidated.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 test_scenicplus_dev",
   "language": "python",
   "name": "test_scenicplus_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
