author: Gary Yang <br>
email: yyang117@jhu.edu <br>
date: 2024-04-28

# Adding a new GRN model

# TODO
- [ ] Update script to accomodate bulk ATAC/DNase-seq
- [ ] Which parameters should I expose to users
- [ ] Dynamic networks needed?



# Dictys GRN inference

# Quick start
1. Modify the config in `config/config.yaml` or create a new one with the same structure
- [ ] Pick a directory to store data and intermediate files generated by Dictys (`working_dir`)
- [ ] Also pick a directory to store final output (`output_dir`)
- [ ] Copy the input Mudata object and fragment file to the `working_dir`
- [ ] Specify the clusters for GRN reconstruction in a list format (`clusters`)
- [ ] Choose the number of threads to use (`n_threads`) based on your system
- [ ] Choose the GPU ID to use (`device`) based on your system

2. Run the pipeline
```bash
snakemake --cores 1 -r download
snakemake --cores 1 -r aggregate_results
```

# Expected input
* `mdata.h5mu` — MuData object in h5mu format containing single-cell multiome data. (see [MuData documentation](https://mudata.readthedocs.io/en/latest/))
    * The MuData object MUST contain the following:
        * `atac` in `mod` -- h5ad for scATAC-seq data
            * `layers["counts"]` — a sparse matrix of raw fragment counts
            * `var_names` — a list of region names in 'chr-start-end' format
        * `rna` in `mod` -- h5ad for scRNA-seq data
            * `layers["counts"]` — a sparse matrix of raw UMI counts
        * `obs` — a dataframe of cell metadata
            * `"celltypes"` — a column of cell type annotations
        * `var` — a dataframe of gene metadata

# Expected output

# Scripts
See below for more details on each step of the CellOracle pipeline.


## `setup_cell_cluster.py` - Set up working directory for individual cell clusters
```bash
python workflow/scripts/setup_cell_cluster.py --mudata {input.data} --data_dir {output.working_dir}
```
- The output is a subset of expression matrix went through Dictys QC metric, a list of cell barcode, and the consensus peak list

## `fragment_to_bam_nofrag.py` — Convert fragment file to bam file
```bash
python workflow/scripts/fragment_to_bam_nofrag.py --cluster_number {wildcards.cluster} --data_dir {input.working_dir} |
samtools view -b | samtools sort -o {output.bam} && samtools index {output.bam} {output.bai} 
```
- When converting fragment file, this script keeps only the fragments associated with cells whose barcode are in names_atac0.txt

## `MACS2` - Call peaks from the bam file
```bash
macs2 callpeak -t {input.bam} -g hs --nomodel --shift -75 --extsize 150 --keep-dup all --verbose 4 
--call-summits -q 0.05 --name reads --outdir {input.working_dir} && 
bedtools intersect -a {input.peak_file} -b {output.macs_peaks} -wa | bedtools sort -i - | uniq > {output.overlap_peaks}
```
- MACS2 is used to call peaks, bedtools is then used to retain peaks that overlap the consensus peak list

## `chromatin_proc.py` — Infer TF-Gene pair by analyzing TF binding at peaks
```bash
python workflow/scripts/chromatin_proc.py --subdir {input.working_dir} --motif {input.motif}
--genome {input.genome} --gene_annotation {input.annotation} --threads {params.n_threads}
```
- Scan peaks to infer TF binding, compute peak distance to closest TSS to infer Peak-Gene linking, finally construct TF-Gene mask

## `infer_grn.py` — Compute TF-Gene regularization weights
```bash
python workflow/scripts/infer_grn.py --subdir {input.directory} --device {params.device} --threads {params.n_threads}
```
- Use the mask computed from the previous step. GPU ought to be used to accelerate this step.

## `aggregate_output.py` — Aggregate all outputs
```bash
python workflow/scripts/aggregate_output.py --mudata {input.data} --input_dir {input.input_dir} --output_dir {output.output_dir}
```

